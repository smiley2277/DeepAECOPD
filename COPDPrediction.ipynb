{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "# print(tf.__version__)\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import joblib\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "from keras.layers.advanced_activations import ReLU, LeakyReLU, PReLU\n",
    "from tensorflow.keras.models import Model\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model #, multi_gpu_model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.5)\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "sess0 = tf.compat.v1.InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./XsmoteTrain.xlsx','rb') as t:\n",
    "    x_train = pd.read_excel(t)\n",
    "    x_columns = x_train.columns\n",
    "with open('./YsmoteTrain.xlsx','rb') as t:\n",
    "    y_train = pd.read_excel(t,squeeze=True)\n",
    "with open('./XsmoteTest.xlsx', 'rb') as f:\n",
    "    x_test = pd.read_excel(f)\n",
    "with open('./YsmoteTest.xlsx', 'rb') as f:\n",
    "    y_test = pd.read_excel(f,squeeze=True)\n",
    "with open('./Xvalid.xlsx', 'rb') as f:\n",
    "    x_valid = pd.read_excel(f)\n",
    "with open('./Yvalid.xlsx', 'rb') as f:\n",
    "    y_valid = pd.read_excel(f,squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tensorboard \n",
    "# tf.summary.histogram('x_test_histogram', x_test)\n",
    "# tf.summary.histogram('x_train_histogram', x_train)\n",
    "\n",
    "##undersampling\n",
    "# from imblearn.under_sampling import RandomUnderSampler \n",
    "# rus = RandomUnderSampler(random_state=42)\n",
    "# x_train, y_train = rus.fit_resample(x_train, y_train)\n",
    "# x_valid, y_valid = rus.fit_resample(x_test, y_test)\n",
    "\n",
    "##transform to float\n",
    "# x_train = K.cast_to_floatx(x_train)\n",
    "# y_train = K.cast_to_floatx(y_train)\n",
    "# x_test = K.cast_to_floatx(x_test)\n",
    "# y_test = K.cast_to_floatx(y_test)\n",
    "# x_valid = K.cast_to_floatx(x_valid)\n",
    "# y_valid = K.cast_to_floatx(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2464, 16) (2464,) (275, 16) (275,)\n"
     ]
    }
   ],
   "source": [
    "##check shape\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,025\n",
      "Trainable params: 929\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph() \n",
    "from tensorflow.keras.activations import relu\n",
    "input_layer = tf.keras.Input(shape=(16,))\n",
    "ly = BatchNormalization()(ly)\n",
    "ly = Dense(16, activation='relu')(input_layer)\n",
    "# ly = relu(ly, alpha=0.2)\n",
    "# ly = BatchNormalization()(ly)\n",
    "# ly = Dense(18, activation='relu')(ly)\n",
    "# ly = relu(ly, alpha=0.2)\n",
    "# ly = BatchNormalization()(ly)\n",
    "# ly = Dense(16, activation='relu')(ly)\n",
    "# ly = relu(ly, alpha=0.2)\n",
    "# ly = BatchNormalization()(ly)\n",
    "# ly = Dense(16, activation='relu')(ly)\n",
    "# ly = relu(ly, alpha=0.2)\n",
    "ly = BatchNormalization()(ly)\n",
    "ly = Dense(16, activation='relu')(ly)\n",
    "ly = BatchNormalization()(ly)\n",
    "ly = Dense(16, activation='relu')(ly)\n",
    "ly = BatchNormalization()(ly)\n",
    "output_layer = Dense(1, activation='sigmoid')(ly)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    lr = K.get_value(model.optimizer.lr)\n",
    "    if epoch % 60 == 0 and epoch != 0:\n",
    "        lr *= 0.1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 5s 46ms/step - loss: 17.8057 - accuracy: 0.4894 - auc: 0.5135 - precision: 0.3865 - recall: 0.6565 - val_loss: 0.7854 - val_accuracy: 0.3709 - val_auc: 0.5323 - val_precision: 0.3633 - val_recall: 0.9029\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78538, saving model to /tmp/param.hdf5\n",
      "Epoch 2/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 15.2443 - accuracy: 0.4590 - auc: 0.5905 - precision: 0.4022 - recall: 0.8487 - val_loss: 0.8774 - val_accuracy: 0.3636 - val_auc: 0.5586 - val_precision: 0.3636 - val_recall: 0.9320\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.78538\n",
      "Epoch 3/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 1s 17ms/step - loss: 14.0181 - accuracy: 0.4488 - auc: 0.6154 - precision: 0.4035 - recall: 0.9591 - val_loss: 0.9361 - val_accuracy: 0.3673 - val_auc: 0.5851 - val_precision: 0.3650 - val_recall: 0.9320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.78538\n",
      "Epoch 4/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 13.5163 - accuracy: 0.4474 - auc: 0.6372 - precision: 0.4015 - recall: 0.9670 - val_loss: 0.9265 - val_accuracy: 0.4109 - val_auc: 0.6177 - val_precision: 0.3870 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.78538\n",
      "Epoch 5/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 13.5050 - accuracy: 0.4121 - auc: 0.6458 - precision: 0.3839 - recall: 0.9680 - val_loss: 0.9345 - val_accuracy: 0.4073 - val_auc: 0.6093 - val_precision: 0.3819 - val_recall: 0.9417\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.78538\n",
      "Epoch 6/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.2165 - accuracy: 0.4416 - auc: 0.6580 - precision: 0.3970 - recall: 0.9762 - val_loss: 0.9128 - val_accuracy: 0.4073 - val_auc: 0.6346 - val_precision: 0.3790 - val_recall: 0.9126\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.78538\n",
      "Epoch 7/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.2232 - accuracy: 0.4435 - auc: 0.6565 - precision: 0.4088 - recall: 0.9740 - val_loss: 0.8908 - val_accuracy: 0.4436 - val_auc: 0.6681 - val_precision: 0.3992 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.78538\n",
      "Epoch 8/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.0933 - accuracy: 0.4431 - auc: 0.6861 - precision: 0.4078 - recall: 0.9672 - val_loss: 0.8914 - val_accuracy: 0.4327 - val_auc: 0.6557 - val_precision: 0.3936 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.78538\n",
      "Epoch 9/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.3804 - accuracy: 0.4429 - auc: 0.6509 - precision: 0.4041 - recall: 0.9720 - val_loss: 0.8858 - val_accuracy: 0.4582 - val_auc: 0.6599 - val_precision: 0.4065 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.78538\n",
      "Epoch 10/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 13.3269 - accuracy: 0.4330 - auc: 0.6579 - precision: 0.3933 - recall: 0.9615 - val_loss: 0.8926 - val_accuracy: 0.4545 - val_auc: 0.6625 - val_precision: 0.4041 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.78538\n",
      "Epoch 11/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.0100 - accuracy: 0.4411 - auc: 0.6833 - precision: 0.3904 - recall: 0.9651 - val_loss: 0.8995 - val_accuracy: 0.4509 - val_auc: 0.6522 - val_precision: 0.4008 - val_recall: 0.9417\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.78538\n",
      "Epoch 12/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.0973 - accuracy: 0.4594 - auc: 0.6623 - precision: 0.4106 - recall: 0.9658 - val_loss: 0.8771 - val_accuracy: 0.4545 - val_auc: 0.6985 - val_precision: 0.4049 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.78538\n",
      "Epoch 13/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9172 - accuracy: 0.4388 - auc: 0.6860 - precision: 0.3930 - recall: 0.9746 - val_loss: 0.8589 - val_accuracy: 0.4836 - val_auc: 0.6768 - val_precision: 0.4184 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.78538\n",
      "Epoch 14/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9827 - accuracy: 0.4440 - auc: 0.6990 - precision: 0.4028 - recall: 0.9615 - val_loss: 0.8788 - val_accuracy: 0.4655 - val_auc: 0.6557 - val_precision: 0.4091 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.78538\n",
      "Epoch 15/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 13.3154 - accuracy: 0.4410 - auc: 0.6587 - precision: 0.3990 - recall: 0.9783 - val_loss: 0.8716 - val_accuracy: 0.4509 - val_auc: 0.6916 - val_precision: 0.4016 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.78538\n",
      "Epoch 16/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7393 - accuracy: 0.4481 - auc: 0.7039 - precision: 0.4010 - recall: 0.9826 - val_loss: 0.9066 - val_accuracy: 0.4509 - val_auc: 0.6673 - val_precision: 0.4032 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.78538\n",
      "Epoch 17/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9393 - accuracy: 0.4457 - auc: 0.7009 - precision: 0.4020 - recall: 0.9607 - val_loss: 0.8952 - val_accuracy: 0.4545 - val_auc: 0.6694 - val_precision: 0.4033 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.78538\n",
      "Epoch 18/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8124 - accuracy: 0.4558 - auc: 0.6983 - precision: 0.4012 - recall: 0.9619 - val_loss: 0.8738 - val_accuracy: 0.4800 - val_auc: 0.6556 - val_precision: 0.4160 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.78538\n",
      "Epoch 19/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9551 - accuracy: 0.4649 - auc: 0.6816 - precision: 0.4138 - recall: 0.9672 - val_loss: 0.8826 - val_accuracy: 0.4727 - val_auc: 0.6638 - val_precision: 0.4118 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.78538\n",
      "Epoch 20/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9202 - accuracy: 0.4522 - auc: 0.6946 - precision: 0.4077 - recall: 0.9650 - val_loss: 0.8744 - val_accuracy: 0.4800 - val_auc: 0.7077 - val_precision: 0.4174 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.78538\n",
      "Epoch 21/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7260 - accuracy: 0.4737 - auc: 0.6991 - precision: 0.4060 - recall: 0.9689 - val_loss: 0.8531 - val_accuracy: 0.4836 - val_auc: 0.7084 - val_precision: 0.4191 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.78538\n",
      "Epoch 22/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8141 - accuracy: 0.4546 - auc: 0.7011 - precision: 0.4036 - recall: 0.9706 - val_loss: 0.8691 - val_accuracy: 0.4582 - val_auc: 0.7188 - val_precision: 0.4073 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.78538\n",
      "Epoch 23/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8141 - accuracy: 0.4655 - auc: 0.7070 - precision: 0.4117 - recall: 0.9624 - val_loss: 0.9085 - val_accuracy: 0.4655 - val_auc: 0.6970 - val_precision: 0.4091 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.78538\n",
      "Epoch 24/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5647 - accuracy: 0.4642 - auc: 0.7177 - precision: 0.4051 - recall: 0.9747 - val_loss: 0.8976 - val_accuracy: 0.4873 - val_auc: 0.7042 - val_precision: 0.4208 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.78538\n",
      "Epoch 25/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9436 - accuracy: 0.4685 - auc: 0.6907 - precision: 0.4159 - recall: 0.9545 - val_loss: 0.8809 - val_accuracy: 0.4691 - val_auc: 0.6804 - val_precision: 0.4085 - val_recall: 0.9320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00025: val_loss did not improve from 0.78538\n",
      "Epoch 26/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6343 - accuracy: 0.4808 - auc: 0.7115 - precision: 0.4159 - recall: 0.9494 - val_loss: 0.8573 - val_accuracy: 0.4691 - val_auc: 0.7029 - val_precision: 0.4093 - val_recall: 0.9417\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.78538\n",
      "Epoch 27/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8111 - accuracy: 0.4859 - auc: 0.6878 - precision: 0.4257 - recall: 0.9652 - val_loss: 0.8975 - val_accuracy: 0.4800 - val_auc: 0.6953 - val_precision: 0.4153 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.78538\n",
      "Epoch 28/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.9808 - accuracy: 0.4861 - auc: 0.6928 - precision: 0.4289 - recall: 0.9510 - val_loss: 0.8301 - val_accuracy: 0.4945 - val_auc: 0.7137 - val_precision: 0.4224 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.78538\n",
      "Epoch 29/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8325 - accuracy: 0.4600 - auc: 0.6905 - precision: 0.3989 - recall: 0.9652 - val_loss: 0.8601 - val_accuracy: 0.4982 - val_auc: 0.7009 - val_precision: 0.4249 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.78538\n",
      "Epoch 30/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7613 - accuracy: 0.4893 - auc: 0.7041 - precision: 0.4266 - recall: 0.9540 - val_loss: 0.8583 - val_accuracy: 0.4800 - val_auc: 0.7130 - val_precision: 0.4167 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.78538\n",
      "Epoch 31/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4395 - accuracy: 0.4915 - auc: 0.7271 - precision: 0.4268 - recall: 0.9759 - val_loss: 0.8443 - val_accuracy: 0.4800 - val_auc: 0.7414 - val_precision: 0.4174 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.78538\n",
      "Epoch 32/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7211 - accuracy: 0.4557 - auc: 0.6966 - precision: 0.3884 - recall: 0.9698 - val_loss: 0.8584 - val_accuracy: 0.4945 - val_auc: 0.6739 - val_precision: 0.4231 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.78538\n",
      "Epoch 33/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6645 - accuracy: 0.4925 - auc: 0.6926 - precision: 0.4310 - recall: 0.9758 - val_loss: 0.8624 - val_accuracy: 0.4945 - val_auc: 0.7233 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.78538\n",
      "Epoch 34/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7913 - accuracy: 0.4967 - auc: 0.6869 - precision: 0.4301 - recall: 0.9685 - val_loss: 0.8580 - val_accuracy: 0.4909 - val_auc: 0.7023 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.78538\n",
      "Epoch 35/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8939 - accuracy: 0.4623 - auc: 0.6890 - precision: 0.4003 - recall: 0.9544 - val_loss: 0.8527 - val_accuracy: 0.4909 - val_auc: 0.7041 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.78538\n",
      "Epoch 36/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8698 - accuracy: 0.4801 - auc: 0.7066 - precision: 0.4230 - recall: 0.9482 - val_loss: 0.8555 - val_accuracy: 0.4982 - val_auc: 0.6904 - val_precision: 0.4255 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.78538\n",
      "Epoch 37/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6785 - accuracy: 0.4706 - auc: 0.6977 - precision: 0.4050 - recall: 0.9602 - val_loss: 0.8484 - val_accuracy: 0.5018 - val_auc: 0.7165 - val_precision: 0.4280 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.78538\n",
      "Epoch 38/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5880 - accuracy: 0.4949 - auc: 0.7227 - precision: 0.4265 - recall: 0.9584 - val_loss: 0.8875 - val_accuracy: 0.4800 - val_auc: 0.7348 - val_precision: 0.4174 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.78538\n",
      "Epoch 39/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2565 - accuracy: 0.5015 - auc: 0.7329 - precision: 0.4301 - recall: 0.9635 - val_loss: 0.8777 - val_accuracy: 0.4945 - val_auc: 0.7351 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.78538\n",
      "Epoch 40/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6042 - accuracy: 0.4808 - auc: 0.7144 - precision: 0.4172 - recall: 0.9484 - val_loss: 0.8362 - val_accuracy: 0.5018 - val_auc: 0.6940 - val_precision: 0.4274 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.78538\n",
      "Epoch 41/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5840 - accuracy: 0.4837 - auc: 0.7116 - precision: 0.4178 - recall: 0.9569 - val_loss: 0.8424 - val_accuracy: 0.4945 - val_auc: 0.7126 - val_precision: 0.4224 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.78538\n",
      "Epoch 42/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3732 - accuracy: 0.4917 - auc: 0.7234 - precision: 0.4218 - recall: 0.9564 - val_loss: 0.8711 - val_accuracy: 0.4982 - val_auc: 0.7076 - val_precision: 0.4262 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.78538\n",
      "Epoch 43/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6198 - accuracy: 0.4756 - auc: 0.7077 - precision: 0.4088 - recall: 0.9562 - val_loss: 0.8548 - val_accuracy: 0.5018 - val_auc: 0.7295 - val_precision: 0.4274 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.78538\n",
      "Epoch 44/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3005 - accuracy: 0.5055 - auc: 0.7383 - precision: 0.4365 - recall: 0.9560 - val_loss: 0.8238 - val_accuracy: 0.4836 - val_auc: 0.6945 - val_precision: 0.4156 - val_recall: 0.9320\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.78538\n",
      "Epoch 45/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4629 - accuracy: 0.4838 - auc: 0.7123 - precision: 0.4185 - recall: 0.9627 - val_loss: 0.8605 - val_accuracy: 0.4909 - val_auc: 0.7326 - val_precision: 0.4219 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.78538\n",
      "Epoch 46/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3443 - accuracy: 0.5030 - auc: 0.7259 - precision: 0.4210 - recall: 0.9698 - val_loss: 0.8563 - val_accuracy: 0.4836 - val_auc: 0.7341 - val_precision: 0.4184 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.78538\n",
      "Epoch 47/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4553 - accuracy: 0.4932 - auc: 0.7176 - precision: 0.4252 - recall: 0.9671 - val_loss: 0.8288 - val_accuracy: 0.4982 - val_auc: 0.7394 - val_precision: 0.4255 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.78538\n",
      "Epoch 48/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7529 - accuracy: 0.4778 - auc: 0.7136 - precision: 0.4118 - recall: 0.9495 - val_loss: 0.8486 - val_accuracy: 0.4982 - val_auc: 0.7035 - val_precision: 0.4255 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.78538\n",
      "Epoch 49/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2860 - accuracy: 0.5070 - auc: 0.7327 - precision: 0.4446 - recall: 0.9643 - val_loss: 0.8432 - val_accuracy: 0.5018 - val_auc: 0.6892 - val_precision: 0.4274 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.78538\n",
      "Epoch 50/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8771 - accuracy: 0.4755 - auc: 0.6897 - precision: 0.4143 - recall: 0.9652 - val_loss: 0.8560 - val_accuracy: 0.5018 - val_auc: 0.7146 - val_precision: 0.4286 - val_recall: 0.9903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00050: val_loss did not improve from 0.78538\n",
      "Epoch 51/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7055 - accuracy: 0.4895 - auc: 0.6994 - precision: 0.4205 - recall: 0.9742 - val_loss: 0.8624 - val_accuracy: 0.5018 - val_auc: 0.7205 - val_precision: 0.4286 - val_recall: 0.9903\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.78538\n",
      "Epoch 52/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.8408 - accuracy: 0.4705 - auc: 0.6956 - precision: 0.4099 - recall: 0.9463 - val_loss: 0.8609 - val_accuracy: 0.4873 - val_auc: 0.7000 - val_precision: 0.4202 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.78538\n",
      "Epoch 53/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6422 - accuracy: 0.4709 - auc: 0.7062 - precision: 0.4069 - recall: 0.9705 - val_loss: 0.8475 - val_accuracy: 0.5091 - val_auc: 0.7114 - val_precision: 0.4316 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.78538\n",
      "Epoch 54/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5969 - accuracy: 0.4742 - auc: 0.7130 - precision: 0.4098 - recall: 0.9682 - val_loss: 0.8790 - val_accuracy: 0.4873 - val_auc: 0.7224 - val_precision: 0.4208 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.78538\n",
      "Epoch 55/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6177 - accuracy: 0.4877 - auc: 0.7109 - precision: 0.4180 - recall: 0.9522 - val_loss: 0.8754 - val_accuracy: 0.4945 - val_auc: 0.6612 - val_precision: 0.4231 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.78538\n",
      "Epoch 56/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4228 - accuracy: 0.4899 - auc: 0.7245 - precision: 0.4220 - recall: 0.9606 - val_loss: 0.8741 - val_accuracy: 0.4836 - val_auc: 0.6978 - val_precision: 0.4177 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.78538\n",
      "Epoch 57/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9919 - accuracy: 0.5160 - auc: 0.7515 - precision: 0.4372 - recall: 0.9712 - val_loss: 0.8127 - val_accuracy: 0.4982 - val_auc: 0.7229 - val_precision: 0.4242 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.78538\n",
      "Epoch 58/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4346 - accuracy: 0.4933 - auc: 0.7231 - precision: 0.4272 - recall: 0.9666 - val_loss: 0.8264 - val_accuracy: 0.4982 - val_auc: 0.7161 - val_precision: 0.4249 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.78538\n",
      "Epoch 59/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3564 - accuracy: 0.4957 - auc: 0.7243 - precision: 0.4211 - recall: 0.9719 - val_loss: 0.8283 - val_accuracy: 0.4909 - val_auc: 0.7208 - val_precision: 0.4219 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.78538\n",
      "Epoch 60/1000\n",
      "Learning rate:  0.001\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2151 - accuracy: 0.4872 - auc: 0.7366 - precision: 0.4131 - recall: 0.9693 - val_loss: 0.8229 - val_accuracy: 0.4982 - val_auc: 0.7350 - val_precision: 0.4255 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.78538\n",
      "Epoch 61/1000\n",
      "Learning rate:  0.00010000000474974513\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4081 - accuracy: 0.5155 - auc: 0.7223 - precision: 0.4410 - recall: 0.9580 - val_loss: 0.8401 - val_accuracy: 0.4982 - val_auc: 0.7245 - val_precision: 0.4255 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.78538\n",
      "Epoch 62/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1642 - accuracy: 0.5017 - auc: 0.7443 - precision: 0.4261 - recall: 0.9684 - val_loss: 0.8407 - val_accuracy: 0.4945 - val_auc: 0.7208 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.78538\n",
      "Epoch 63/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1953 - accuracy: 0.5007 - auc: 0.7377 - precision: 0.4256 - recall: 0.9693 - val_loss: 0.8426 - val_accuracy: 0.4945 - val_auc: 0.7191 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.78538\n",
      "Epoch 64/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2644 - accuracy: 0.5250 - auc: 0.7326 - precision: 0.4454 - recall: 0.9641 - val_loss: 0.8437 - val_accuracy: 0.4982 - val_auc: 0.7162 - val_precision: 0.4255 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.78538\n",
      "Epoch 65/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4805 - accuracy: 0.5096 - auc: 0.7207 - precision: 0.4388 - recall: 0.9564 - val_loss: 0.8505 - val_accuracy: 0.4945 - val_auc: 0.7140 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.78538\n",
      "Epoch 66/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0225 - accuracy: 0.5165 - auc: 0.7477 - precision: 0.4410 - recall: 0.9705 - val_loss: 0.8489 - val_accuracy: 0.4909 - val_auc: 0.7168 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.78538\n",
      "Epoch 67/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3135 - accuracy: 0.5186 - auc: 0.7306 - precision: 0.4437 - recall: 0.9543 - val_loss: 0.8447 - val_accuracy: 0.4945 - val_auc: 0.7160 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.78538\n",
      "Epoch 68/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0969 - accuracy: 0.4934 - auc: 0.7416 - precision: 0.4115 - recall: 0.9685 - val_loss: 0.8466 - val_accuracy: 0.4945 - val_auc: 0.7116 - val_precision: 0.4237 - val_recall: 0.9709\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.78538\n",
      "Epoch 69/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1062 - accuracy: 0.4906 - auc: 0.7443 - precision: 0.4152 - recall: 0.9640 - val_loss: 0.8501 - val_accuracy: 0.4909 - val_auc: 0.7091 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.78538\n",
      "Epoch 70/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3318 - accuracy: 0.4957 - auc: 0.7287 - precision: 0.4152 - recall: 0.9594 - val_loss: 0.8465 - val_accuracy: 0.4909 - val_auc: 0.7023 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.78538\n",
      "Epoch 71/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1731 - accuracy: 0.4961 - auc: 0.7389 - precision: 0.4204 - recall: 0.9700 - val_loss: 0.8490 - val_accuracy: 0.4909 - val_auc: 0.7048 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.78538\n",
      "Epoch 72/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3025 - accuracy: 0.4895 - auc: 0.7364 - precision: 0.4163 - recall: 0.9474 - val_loss: 0.8463 - val_accuracy: 0.4909 - val_auc: 0.7025 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.78538\n",
      "Epoch 73/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3407 - accuracy: 0.5078 - auc: 0.7240 - precision: 0.4280 - recall: 0.9565 - val_loss: 0.8496 - val_accuracy: 0.4909 - val_auc: 0.7001 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.78538\n",
      "Epoch 74/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.5734 - accuracy: 0.5120 - auc: 0.7116 - precision: 0.4400 - recall: 0.9544 - val_loss: 0.8425 - val_accuracy: 0.4873 - val_auc: 0.6996 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.78538\n",
      "Epoch 75/1000\n",
      "Learning rate:  0.000100000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2838 - accuracy: 0.5015 - auc: 0.7275 - precision: 0.4282 - recall: 0.9564 - val_loss: 0.8407 - val_accuracy: 0.4873 - val_auc: 0.6996 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.78538\n",
      "Epoch 76/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9923 - accuracy: 0.5126 - auc: 0.7488 - precision: 0.4371 - recall: 0.9673 - val_loss: 0.8434 - val_accuracy: 0.4873 - val_auc: 0.7017 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.78538\n",
      "Epoch 77/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2294 - accuracy: 0.5170 - auc: 0.7415 - precision: 0.4467 - recall: 0.9527 - val_loss: 0.8456 - val_accuracy: 0.4909 - val_auc: 0.7011 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.78538\n",
      "Epoch 78/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4165 - accuracy: 0.4940 - auc: 0.7260 - precision: 0.4247 - recall: 0.9408 - val_loss: 0.8424 - val_accuracy: 0.4909 - val_auc: 0.7076 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.78538\n",
      "Epoch 79/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1535 - accuracy: 0.5043 - auc: 0.7389 - precision: 0.4189 - recall: 0.9710 - val_loss: 0.8456 - val_accuracy: 0.4909 - val_auc: 0.7029 - val_precision: 0.4213 - val_recall: 0.9612\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.78538\n",
      "Epoch 80/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0942 - accuracy: 0.5181 - auc: 0.7433 - precision: 0.4360 - recall: 0.9622 - val_loss: 0.8472 - val_accuracy: 0.4873 - val_auc: 0.7054 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.78538\n",
      "Epoch 81/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.3609 - accuracy: 0.4939 - auc: 0.7231 - precision: 0.4187 - recall: 0.9512 - val_loss: 0.8469 - val_accuracy: 0.4873 - val_auc: 0.7038 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.78538\n",
      "Epoch 82/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0253 - accuracy: 0.5109 - auc: 0.7449 - precision: 0.4273 - recall: 0.9677 - val_loss: 0.8465 - val_accuracy: 0.4873 - val_auc: 0.7050 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.78538\n",
      "Epoch 83/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2762 - accuracy: 0.5017 - auc: 0.7277 - precision: 0.4290 - recall: 0.9627 - val_loss: 0.8494 - val_accuracy: 0.4873 - val_auc: 0.7049 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.78538\n",
      "Epoch 84/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2600 - accuracy: 0.5043 - auc: 0.7384 - precision: 0.4265 - recall: 0.9581 - val_loss: 0.8505 - val_accuracy: 0.4873 - val_auc: 0.7022 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.78538\n",
      "Epoch 85/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4297 - accuracy: 0.5091 - auc: 0.7161 - precision: 0.4403 - recall: 0.9705 - val_loss: 0.8546 - val_accuracy: 0.4873 - val_auc: 0.7026 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.78538\n",
      "Epoch 86/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8169 - accuracy: 0.5205 - auc: 0.7611 - precision: 0.4420 - recall: 0.9723 - val_loss: 0.8455 - val_accuracy: 0.4873 - val_auc: 0.7035 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.78538\n",
      "Epoch 87/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5731 - accuracy: 0.5061 - auc: 0.7088 - precision: 0.4391 - recall: 0.9575 - val_loss: 0.8419 - val_accuracy: 0.4873 - val_auc: 0.7120 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.78538\n",
      "Epoch 88/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0643 - accuracy: 0.5096 - auc: 0.7462 - precision: 0.4360 - recall: 0.9726 - val_loss: 0.8434 - val_accuracy: 0.4873 - val_auc: 0.7087 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.78538\n",
      "Epoch 89/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3516 - accuracy: 0.5076 - auc: 0.7222 - precision: 0.4273 - recall: 0.9569 - val_loss: 0.8400 - val_accuracy: 0.4873 - val_auc: 0.7088 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.78538\n",
      "Epoch 90/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4271 - accuracy: 0.4905 - auc: 0.7284 - precision: 0.4165 - recall: 0.9466 - val_loss: 0.8434 - val_accuracy: 0.4873 - val_auc: 0.7126 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.78538\n",
      "Epoch 91/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5296 - accuracy: 0.5118 - auc: 0.7223 - precision: 0.4422 - recall: 0.9467 - val_loss: 0.8506 - val_accuracy: 0.4836 - val_auc: 0.7045 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.78538\n",
      "Epoch 92/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1111 - accuracy: 0.5011 - auc: 0.7528 - precision: 0.4244 - recall: 0.9531 - val_loss: 0.8505 - val_accuracy: 0.4836 - val_auc: 0.7022 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.78538\n",
      "Epoch 93/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5594 - accuracy: 0.4776 - auc: 0.7185 - precision: 0.4040 - recall: 0.9553 - val_loss: 0.8391 - val_accuracy: 0.4836 - val_auc: 0.7083 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.78538\n",
      "Epoch 94/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4922 - accuracy: 0.4997 - auc: 0.7297 - precision: 0.4300 - recall: 0.9513 - val_loss: 0.8452 - val_accuracy: 0.4873 - val_auc: 0.7103 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.78538\n",
      "Epoch 95/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2698 - accuracy: 0.5091 - auc: 0.7398 - precision: 0.4309 - recall: 0.9596 - val_loss: 0.8439 - val_accuracy: 0.4873 - val_auc: 0.7108 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.78538\n",
      "Epoch 96/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4768 - accuracy: 0.4920 - auc: 0.7221 - precision: 0.4150 - recall: 0.9563 - val_loss: 0.8446 - val_accuracy: 0.4873 - val_auc: 0.7098 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.78538\n",
      "Epoch 97/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0100 - accuracy: 0.5018 - auc: 0.7502 - precision: 0.4207 - recall: 0.9717 - val_loss: 0.8510 - val_accuracy: 0.4873 - val_auc: 0.7061 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.78538\n",
      "Epoch 98/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3262 - accuracy: 0.5023 - auc: 0.7314 - precision: 0.4278 - recall: 0.9566 - val_loss: 0.8464 - val_accuracy: 0.4873 - val_auc: 0.7081 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.78538\n",
      "Epoch 99/1000\n",
      "Learning rate:  0.000100000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2469 - accuracy: 0.5057 - auc: 0.7314 - precision: 0.4259 - recall: 0.9621 - val_loss: 0.8483 - val_accuracy: 0.4873 - val_auc: 0.7092 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.78538\n",
      "Epoch 100/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0040 - accuracy: 0.5055 - auc: 0.7489 - precision: 0.4177 - recall: 0.9692 - val_loss: 0.8439 - val_accuracy: 0.4873 - val_auc: 0.7137 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.78538\n",
      "Epoch 101/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2845 - accuracy: 0.5072 - auc: 0.7335 - precision: 0.4356 - recall: 0.9576 - val_loss: 0.8418 - val_accuracy: 0.4873 - val_auc: 0.7125 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.78538\n",
      "Epoch 102/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6229 - accuracy: 0.5128 - auc: 0.7145 - precision: 0.4423 - recall: 0.9473 - val_loss: 0.8458 - val_accuracy: 0.4873 - val_auc: 0.7086 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.78538\n",
      "Epoch 103/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1768 - accuracy: 0.5211 - auc: 0.7356 - precision: 0.4438 - recall: 0.9662 - val_loss: 0.8428 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.78538\n",
      "Epoch 104/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2957 - accuracy: 0.5104 - auc: 0.7294 - precision: 0.4331 - recall: 0.9635 - val_loss: 0.8416 - val_accuracy: 0.4873 - val_auc: 0.7095 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.78538\n",
      "Epoch 105/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0631 - accuracy: 0.4929 - auc: 0.7454 - precision: 0.4098 - recall: 0.9621 - val_loss: 0.8463 - val_accuracy: 0.4873 - val_auc: 0.7111 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.78538\n",
      "Epoch 106/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1284 - accuracy: 0.5026 - auc: 0.7434 - precision: 0.4246 - recall: 0.9594 - val_loss: 0.8451 - val_accuracy: 0.4873 - val_auc: 0.7105 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.78538\n",
      "Epoch 107/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5578 - accuracy: 0.5082 - auc: 0.7157 - precision: 0.4302 - recall: 0.9506 - val_loss: 0.8438 - val_accuracy: 0.4836 - val_auc: 0.7129 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.78538\n",
      "Epoch 108/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1324 - accuracy: 0.5172 - auc: 0.7435 - precision: 0.4353 - recall: 0.9684 - val_loss: 0.8446 - val_accuracy: 0.4836 - val_auc: 0.7117 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.78538\n",
      "Epoch 109/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4633 - accuracy: 0.5254 - auc: 0.7213 - precision: 0.4528 - recall: 0.9529 - val_loss: 0.8471 - val_accuracy: 0.4873 - val_auc: 0.7074 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.78538\n",
      "Epoch 110/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3194 - accuracy: 0.5098 - auc: 0.7263 - precision: 0.4342 - recall: 0.9593 - val_loss: 0.8502 - val_accuracy: 0.4873 - val_auc: 0.7080 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.78538\n",
      "Epoch 111/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4019 - accuracy: 0.5115 - auc: 0.7165 - precision: 0.4324 - recall: 0.9599 - val_loss: 0.8446 - val_accuracy: 0.4873 - val_auc: 0.7084 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.78538\n",
      "Epoch 112/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3705 - accuracy: 0.5071 - auc: 0.7232 - precision: 0.4199 - recall: 0.9618 - val_loss: 0.8457 - val_accuracy: 0.4909 - val_auc: 0.7021 - val_precision: 0.4206 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.78538\n",
      "Epoch 113/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4863 - accuracy: 0.5066 - auc: 0.7256 - precision: 0.4264 - recall: 0.9497 - val_loss: 0.8495 - val_accuracy: 0.4873 - val_auc: 0.7039 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.78538\n",
      "Epoch 114/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0904 - accuracy: 0.5142 - auc: 0.7447 - precision: 0.4260 - recall: 0.9688 - val_loss: 0.8547 - val_accuracy: 0.4909 - val_auc: 0.6975 - val_precision: 0.4206 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.78538\n",
      "Epoch 115/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4348 - accuracy: 0.5043 - auc: 0.7225 - precision: 0.4297 - recall: 0.9467 - val_loss: 0.8484 - val_accuracy: 0.4873 - val_auc: 0.7040 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.78538\n",
      "Epoch 116/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4443 - accuracy: 0.5025 - auc: 0.7204 - precision: 0.4216 - recall: 0.9551 - val_loss: 0.8445 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.78538\n",
      "Epoch 117/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2915 - accuracy: 0.5075 - auc: 0.7302 - precision: 0.4260 - recall: 0.9521 - val_loss: 0.8511 - val_accuracy: 0.4836 - val_auc: 0.7023 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.78538\n",
      "Epoch 118/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2310 - accuracy: 0.4892 - auc: 0.7391 - precision: 0.4124 - recall: 0.9478 - val_loss: 0.8520 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.78538\n",
      "Epoch 119/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3362 - accuracy: 0.5037 - auc: 0.7293 - precision: 0.4239 - recall: 0.9503 - val_loss: 0.8528 - val_accuracy: 0.4873 - val_auc: 0.7025 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.78538\n",
      "Epoch 120/1000\n",
      "Learning rate:  0.000100000005\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4795 - accuracy: 0.5167 - auc: 0.7090 - precision: 0.4367 - recall: 0.9593 - val_loss: 0.8475 - val_accuracy: 0.4873 - val_auc: 0.7079 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.78538\n",
      "Epoch 121/1000\n",
      "Learning rate:  1.0000000474974514e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2612 - accuracy: 0.5221 - auc: 0.7307 - precision: 0.4419 - recall: 0.9584 - val_loss: 0.8470 - val_accuracy: 0.4873 - val_auc: 0.7041 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.78538\n",
      "Epoch 122/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3513 - accuracy: 0.5095 - auc: 0.7310 - precision: 0.4338 - recall: 0.9566 - val_loss: 0.8473 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.78538\n",
      "Epoch 123/1000\n",
      "Learning rate:  1.0000001e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3050 - accuracy: 0.5020 - auc: 0.7303 - precision: 0.4280 - recall: 0.9535 - val_loss: 0.8519 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.78538\n",
      "Epoch 124/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2420 - accuracy: 0.4998 - auc: 0.7355 - precision: 0.4260 - recall: 0.9665 - val_loss: 0.8559 - val_accuracy: 0.4873 - val_auc: 0.7051 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.78538\n",
      "Epoch 125/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0091 - accuracy: 0.5116 - auc: 0.7463 - precision: 0.4236 - recall: 0.9657 - val_loss: 0.8545 - val_accuracy: 0.4873 - val_auc: 0.7043 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.78538\n",
      "Epoch 126/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2807 - accuracy: 0.5029 - auc: 0.7349 - precision: 0.4228 - recall: 0.9608 - val_loss: 0.8588 - val_accuracy: 0.4873 - val_auc: 0.7063 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.78538\n",
      "Epoch 127/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1136 - accuracy: 0.5128 - auc: 0.7389 - precision: 0.4213 - recall: 0.9684 - val_loss: 0.8523 - val_accuracy: 0.4873 - val_auc: 0.7046 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.78538\n",
      "Epoch 128/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3835 - accuracy: 0.5064 - auc: 0.7213 - precision: 0.4303 - recall: 0.9556 - val_loss: 0.8563 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.78538\n",
      "Epoch 129/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2787 - accuracy: 0.5106 - auc: 0.7444 - precision: 0.4339 - recall: 0.9594 - val_loss: 0.8497 - val_accuracy: 0.4873 - val_auc: 0.7053 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.78538\n",
      "Epoch 130/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0593 - accuracy: 0.5231 - auc: 0.7377 - precision: 0.4397 - recall: 0.9718 - val_loss: 0.8452 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.78538\n",
      "Epoch 131/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1109 - accuracy: 0.5106 - auc: 0.7330 - precision: 0.4318 - recall: 0.9689 - val_loss: 0.8477 - val_accuracy: 0.4873 - val_auc: 0.7050 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.78538\n",
      "Epoch 132/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2845 - accuracy: 0.4993 - auc: 0.7324 - precision: 0.4198 - recall: 0.9637 - val_loss: 0.8493 - val_accuracy: 0.4873 - val_auc: 0.7028 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.78538\n",
      "Epoch 133/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3729 - accuracy: 0.5017 - auc: 0.7197 - precision: 0.4238 - recall: 0.9607 - val_loss: 0.8494 - val_accuracy: 0.4873 - val_auc: 0.7042 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.78538\n",
      "Epoch 134/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4000 - accuracy: 0.5230 - auc: 0.7244 - precision: 0.4515 - recall: 0.9592 - val_loss: 0.8492 - val_accuracy: 0.4873 - val_auc: 0.7038 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.78538\n",
      "Epoch 135/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1916 - accuracy: 0.5106 - auc: 0.7439 - precision: 0.4282 - recall: 0.9483 - val_loss: 0.8457 - val_accuracy: 0.4873 - val_auc: 0.7058 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.78538\n",
      "Epoch 136/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0624 - accuracy: 0.5093 - auc: 0.7436 - precision: 0.4224 - recall: 0.9771 - val_loss: 0.8441 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.78538\n",
      "Epoch 137/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3219 - accuracy: 0.5097 - auc: 0.7226 - precision: 0.4278 - recall: 0.9592 - val_loss: 0.8445 - val_accuracy: 0.4873 - val_auc: 0.7033 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.78538\n",
      "Epoch 138/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0841 - accuracy: 0.5187 - auc: 0.7457 - precision: 0.4410 - recall: 0.9504 - val_loss: 0.8452 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.78538\n",
      "Epoch 139/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1073 - accuracy: 0.5156 - auc: 0.7446 - precision: 0.4347 - recall: 0.9609 - val_loss: 0.8451 - val_accuracy: 0.4873 - val_auc: 0.7062 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.78538\n",
      "Epoch 140/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2312 - accuracy: 0.5077 - auc: 0.7461 - precision: 0.4275 - recall: 0.9544 - val_loss: 0.8498 - val_accuracy: 0.4873 - val_auc: 0.7032 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.78538\n",
      "Epoch 141/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2581 - accuracy: 0.5221 - auc: 0.7384 - precision: 0.4421 - recall: 0.9552 - val_loss: 0.8517 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.78538\n",
      "Epoch 142/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1425 - accuracy: 0.5132 - auc: 0.7362 - precision: 0.4307 - recall: 0.9622 - val_loss: 0.8515 - val_accuracy: 0.4873 - val_auc: 0.7023 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.78538\n",
      "Epoch 143/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2929 - accuracy: 0.5129 - auc: 0.7286 - precision: 0.4318 - recall: 0.9532 - val_loss: 0.8507 - val_accuracy: 0.4873 - val_auc: 0.7013 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.78538\n",
      "Epoch 144/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8570 - accuracy: 0.5056 - auc: 0.7661 - precision: 0.4275 - recall: 0.9652 - val_loss: 0.8534 - val_accuracy: 0.4873 - val_auc: 0.7017 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.78538\n",
      "Epoch 145/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3551 - accuracy: 0.5279 - auc: 0.7260 - precision: 0.4548 - recall: 0.9677 - val_loss: 0.8521 - val_accuracy: 0.4873 - val_auc: 0.7042 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.78538\n",
      "Epoch 146/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2153 - accuracy: 0.5020 - auc: 0.7371 - precision: 0.4229 - recall: 0.9611 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7025 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.78538\n",
      "Epoch 147/1000\n",
      "Learning rate:  1.0000001e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0623 - accuracy: 0.5167 - auc: 0.7489 - precision: 0.4361 - recall: 0.9637 - val_loss: 0.8501 - val_accuracy: 0.4873 - val_auc: 0.7057 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.78538\n",
      "Epoch 148/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4170 - accuracy: 0.5044 - auc: 0.7258 - precision: 0.4265 - recall: 0.9669 - val_loss: 0.8486 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.78538\n",
      "Epoch 149/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0567 - accuracy: 0.5260 - auc: 0.7468 - precision: 0.4492 - recall: 0.9675 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.78538\n",
      "Epoch 150/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2262 - accuracy: 0.5038 - auc: 0.7348 - precision: 0.4249 - recall: 0.9607 - val_loss: 0.8482 - val_accuracy: 0.4873 - val_auc: 0.7034 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.78538\n",
      "Epoch 151/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9103 - accuracy: 0.5058 - auc: 0.7582 - precision: 0.4286 - recall: 0.9664 - val_loss: 0.8521 - val_accuracy: 0.4873 - val_auc: 0.7068 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.78538\n",
      "Epoch 152/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1152 - accuracy: 0.5136 - auc: 0.7423 - precision: 0.4390 - recall: 0.9563 - val_loss: 0.8514 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.78538\n",
      "Epoch 153/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8708 - accuracy: 0.5134 - auc: 0.7584 - precision: 0.4230 - recall: 0.9732 - val_loss: 0.8578 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.78538\n",
      "Epoch 154/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1549 - accuracy: 0.5054 - auc: 0.7455 - precision: 0.4276 - recall: 0.9548 - val_loss: 0.8508 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.78538\n",
      "Epoch 155/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4094 - accuracy: 0.5050 - auc: 0.7201 - precision: 0.4254 - recall: 0.9444 - val_loss: 0.8503 - val_accuracy: 0.4873 - val_auc: 0.7054 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.78538\n",
      "Epoch 156/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0786 - accuracy: 0.5109 - auc: 0.7395 - precision: 0.4353 - recall: 0.9673 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7011 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.78538\n",
      "Epoch 157/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0471 - accuracy: 0.5125 - auc: 0.7427 - precision: 0.4295 - recall: 0.9664 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7010 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.78538\n",
      "Epoch 158/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0602 - accuracy: 0.5160 - auc: 0.7418 - precision: 0.4328 - recall: 0.9621 - val_loss: 0.8527 - val_accuracy: 0.4873 - val_auc: 0.7024 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.78538\n",
      "Epoch 159/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2737 - accuracy: 0.5019 - auc: 0.7312 - precision: 0.4168 - recall: 0.9558 - val_loss: 0.8509 - val_accuracy: 0.4873 - val_auc: 0.7022 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.78538\n",
      "Epoch 160/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2583 - accuracy: 0.5053 - auc: 0.7371 - precision: 0.4225 - recall: 0.9644 - val_loss: 0.8544 - val_accuracy: 0.4873 - val_auc: 0.7010 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.78538\n",
      "Epoch 161/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1868 - accuracy: 0.5140 - auc: 0.7351 - precision: 0.4356 - recall: 0.9602 - val_loss: 0.8515 - val_accuracy: 0.4873 - val_auc: 0.7008 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.78538\n",
      "Epoch 162/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4699 - accuracy: 0.4969 - auc: 0.7289 - precision: 0.4217 - recall: 0.9547 - val_loss: 0.8527 - val_accuracy: 0.4873 - val_auc: 0.6996 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.78538\n",
      "Epoch 163/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3316 - accuracy: 0.4949 - auc: 0.7257 - precision: 0.4151 - recall: 0.9602 - val_loss: 0.8587 - val_accuracy: 0.4873 - val_auc: 0.6967 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.78538\n",
      "Epoch 164/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4466 - accuracy: 0.5071 - auc: 0.7241 - precision: 0.4254 - recall: 0.9463 - val_loss: 0.8521 - val_accuracy: 0.4873 - val_auc: 0.6998 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.78538\n",
      "Epoch 165/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3137 - accuracy: 0.5084 - auc: 0.7282 - precision: 0.4294 - recall: 0.9609 - val_loss: 0.8491 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.78538\n",
      "Epoch 166/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2070 - accuracy: 0.5160 - auc: 0.7299 - precision: 0.4332 - recall: 0.9681 - val_loss: 0.8509 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.78538\n",
      "Epoch 167/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0597 - accuracy: 0.5000 - auc: 0.7492 - precision: 0.4161 - recall: 0.9580 - val_loss: 0.8510 - val_accuracy: 0.4873 - val_auc: 0.7026 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.78538\n",
      "Epoch 168/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0183 - accuracy: 0.5179 - auc: 0.7474 - precision: 0.4360 - recall: 0.9649 - val_loss: 0.8442 - val_accuracy: 0.4873 - val_auc: 0.7054 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.78538\n",
      "Epoch 169/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1989 - accuracy: 0.5075 - auc: 0.7359 - precision: 0.4334 - recall: 0.9663 - val_loss: 0.8450 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.78538\n",
      "Epoch 170/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2060 - accuracy: 0.5081 - auc: 0.7455 - precision: 0.4261 - recall: 0.9565 - val_loss: 0.8462 - val_accuracy: 0.4873 - val_auc: 0.7066 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.78538\n",
      "Epoch 171/1000\n",
      "Learning rate:  1.0000001e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3528 - accuracy: 0.4921 - auc: 0.7333 - precision: 0.4111 - recall: 0.9544 - val_loss: 0.8461 - val_accuracy: 0.4836 - val_auc: 0.7047 - val_precision: 0.4163 - val_recall: 0.9417\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.78538\n",
      "Epoch 172/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0180 - accuracy: 0.5275 - auc: 0.7403 - precision: 0.4491 - recall: 0.9700 - val_loss: 0.8436 - val_accuracy: 0.4873 - val_auc: 0.7060 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.78538\n",
      "Epoch 173/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2958 - accuracy: 0.5112 - auc: 0.7262 - precision: 0.4274 - recall: 0.9541 - val_loss: 0.8458 - val_accuracy: 0.4873 - val_auc: 0.7050 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.78538\n",
      "Epoch 174/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9893 - accuracy: 0.5208 - auc: 0.7440 - precision: 0.4392 - recall: 0.9733 - val_loss: 0.8452 - val_accuracy: 0.4873 - val_auc: 0.7068 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.78538\n",
      "Epoch 175/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9461 - accuracy: 0.5170 - auc: 0.7522 - precision: 0.4317 - recall: 0.9731 - val_loss: 0.8525 - val_accuracy: 0.4836 - val_auc: 0.7044 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.78538\n",
      "Epoch 176/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4524 - accuracy: 0.4937 - auc: 0.7233 - precision: 0.4211 - recall: 0.9543 - val_loss: 0.8518 - val_accuracy: 0.4836 - val_auc: 0.7060 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.78538\n",
      "Epoch 177/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3080 - accuracy: 0.5128 - auc: 0.7311 - precision: 0.4272 - recall: 0.9685 - val_loss: 0.8510 - val_accuracy: 0.4873 - val_auc: 0.7058 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.78538\n",
      "Epoch 178/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2297 - accuracy: 0.4988 - auc: 0.7393 - precision: 0.4192 - recall: 0.9533 - val_loss: 0.8489 - val_accuracy: 0.4873 - val_auc: 0.7054 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.78538\n",
      "Epoch 179/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1152 - accuracy: 0.5064 - auc: 0.7382 - precision: 0.4262 - recall: 0.9688 - val_loss: 0.8474 - val_accuracy: 0.4873 - val_auc: 0.7024 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.78538\n",
      "Epoch 180/1000\n",
      "Learning rate:  1.0000001e-05\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1119 - accuracy: 0.5077 - auc: 0.7399 - precision: 0.4256 - recall: 0.9642 - val_loss: 0.8504 - val_accuracy: 0.4873 - val_auc: 0.7009 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.78538\n",
      "Epoch 181/1000\n",
      "Learning rate:  1.0000000656873453e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3213 - accuracy: 0.5075 - auc: 0.7255 - precision: 0.4302 - recall: 0.9585 - val_loss: 0.8534 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.78538\n",
      "Epoch 182/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1937 - accuracy: 0.5207 - auc: 0.7354 - precision: 0.4435 - recall: 0.9559 - val_loss: 0.8521 - val_accuracy: 0.4873 - val_auc: 0.7013 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.78538\n",
      "Epoch 183/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0774 - accuracy: 0.5070 - auc: 0.7462 - precision: 0.4287 - recall: 0.9565 - val_loss: 0.8591 - val_accuracy: 0.4873 - val_auc: 0.7009 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.78538\n",
      "Epoch 184/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1521 - accuracy: 0.5094 - auc: 0.7491 - precision: 0.4327 - recall: 0.9441 - val_loss: 0.8562 - val_accuracy: 0.4873 - val_auc: 0.7061 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.78538\n",
      "Epoch 185/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3136 - accuracy: 0.5074 - auc: 0.7243 - precision: 0.4310 - recall: 0.9624 - val_loss: 0.8523 - val_accuracy: 0.4873 - val_auc: 0.7049 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.78538\n",
      "Epoch 186/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.7920 - accuracy: 0.5151 - auc: 0.7583 - precision: 0.4303 - recall: 0.9752 - val_loss: 0.8494 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.78538\n",
      "Epoch 187/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3336 - accuracy: 0.5094 - auc: 0.7271 - precision: 0.4313 - recall: 0.9626 - val_loss: 0.8473 - val_accuracy: 0.4873 - val_auc: 0.7059 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.78538\n",
      "Epoch 188/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1425 - accuracy: 0.5151 - auc: 0.7425 - precision: 0.4365 - recall: 0.9484 - val_loss: 0.8483 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.78538\n",
      "Epoch 189/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0387 - accuracy: 0.5214 - auc: 0.7486 - precision: 0.4419 - recall: 0.9583 - val_loss: 0.8515 - val_accuracy: 0.4873 - val_auc: 0.7034 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.78538\n",
      "Epoch 190/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9969 - accuracy: 0.4964 - auc: 0.7512 - precision: 0.4202 - recall: 0.9644 - val_loss: 0.8527 - val_accuracy: 0.4873 - val_auc: 0.7007 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.78538\n",
      "Epoch 191/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1009 - accuracy: 0.5144 - auc: 0.7344 - precision: 0.4305 - recall: 0.9664 - val_loss: 0.8509 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.78538\n",
      "Epoch 192/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2630 - accuracy: 0.5082 - auc: 0.7281 - precision: 0.4288 - recall: 0.9665 - val_loss: 0.8472 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.78538\n",
      "Epoch 193/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4061 - accuracy: 0.5064 - auc: 0.7307 - precision: 0.4259 - recall: 0.9481 - val_loss: 0.8440 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.78538\n",
      "Epoch 194/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6082 - accuracy: 0.5042 - auc: 0.7240 - precision: 0.4241 - recall: 0.9456 - val_loss: 0.8472 - val_accuracy: 0.4873 - val_auc: 0.7049 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.78538\n",
      "Epoch 195/1000\n",
      "Learning rate:  1.0000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2016 - accuracy: 0.5211 - auc: 0.7356 - precision: 0.4471 - recall: 0.9665 - val_loss: 0.8449 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.78538\n",
      "Epoch 196/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0728 - accuracy: 0.5085 - auc: 0.7591 - precision: 0.4316 - recall: 0.9527 - val_loss: 0.8490 - val_accuracy: 0.4873 - val_auc: 0.7028 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.78538\n",
      "Epoch 197/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2022 - accuracy: 0.5072 - auc: 0.7399 - precision: 0.4331 - recall: 0.9605 - val_loss: 0.8526 - val_accuracy: 0.4873 - val_auc: 0.7006 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.78538\n",
      "Epoch 198/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0747 - accuracy: 0.5120 - auc: 0.7450 - precision: 0.4303 - recall: 0.9565 - val_loss: 0.8527 - val_accuracy: 0.4873 - val_auc: 0.7009 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.78538\n",
      "Epoch 199/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0496 - accuracy: 0.5261 - auc: 0.7493 - precision: 0.4469 - recall: 0.9507 - val_loss: 0.8513 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.78538\n",
      "Epoch 200/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3085 - accuracy: 0.5095 - auc: 0.7341 - precision: 0.4246 - recall: 0.9600 - val_loss: 0.8476 - val_accuracy: 0.4873 - val_auc: 0.7024 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.78538\n",
      "Epoch 201/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1952 - accuracy: 0.5211 - auc: 0.7418 - precision: 0.4441 - recall: 0.9523 - val_loss: 0.8503 - val_accuracy: 0.4873 - val_auc: 0.7000 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.78538\n",
      "Epoch 202/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5699 - accuracy: 0.5006 - auc: 0.7326 - precision: 0.4342 - recall: 0.9368 - val_loss: 0.8512 - val_accuracy: 0.4873 - val_auc: 0.7036 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.78538\n",
      "Epoch 203/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2579 - accuracy: 0.5129 - auc: 0.7326 - precision: 0.4338 - recall: 0.9649 - val_loss: 0.8509 - val_accuracy: 0.4873 - val_auc: 0.7027 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.78538\n",
      "Epoch 204/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2870 - accuracy: 0.5153 - auc: 0.7322 - precision: 0.4343 - recall: 0.9555 - val_loss: 0.8480 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.78538\n",
      "Epoch 205/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2627 - accuracy: 0.5167 - auc: 0.7307 - precision: 0.4400 - recall: 0.9602 - val_loss: 0.8504 - val_accuracy: 0.4873 - val_auc: 0.7021 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.78538\n",
      "Epoch 206/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8199 - accuracy: 0.5257 - auc: 0.7613 - precision: 0.4425 - recall: 0.9688 - val_loss: 0.8504 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.78538\n",
      "Epoch 207/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0318 - accuracy: 0.5218 - auc: 0.7439 - precision: 0.4448 - recall: 0.9718 - val_loss: 0.8504 - val_accuracy: 0.4873 - val_auc: 0.7062 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.78538\n",
      "Epoch 208/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1346 - accuracy: 0.5246 - auc: 0.7396 - precision: 0.4527 - recall: 0.9572 - val_loss: 0.8516 - val_accuracy: 0.4873 - val_auc: 0.7057 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.78538\n",
      "Epoch 209/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1778 - accuracy: 0.5242 - auc: 0.7437 - precision: 0.4465 - recall: 0.9545 - val_loss: 0.8492 - val_accuracy: 0.4873 - val_auc: 0.7051 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.78538\n",
      "Epoch 210/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4802 - accuracy: 0.5018 - auc: 0.7200 - precision: 0.4265 - recall: 0.9420 - val_loss: 0.8462 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.78538\n",
      "Epoch 211/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2585 - accuracy: 0.5148 - auc: 0.7267 - precision: 0.4363 - recall: 0.9684 - val_loss: 0.8429 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.78538\n",
      "Epoch 212/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2531 - accuracy: 0.5202 - auc: 0.7332 - precision: 0.4410 - recall: 0.9655 - val_loss: 0.8476 - val_accuracy: 0.4873 - val_auc: 0.7038 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.78538\n",
      "Epoch 213/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2432 - accuracy: 0.5068 - auc: 0.7297 - precision: 0.4277 - recall: 0.9591 - val_loss: 0.8478 - val_accuracy: 0.4873 - val_auc: 0.7051 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.78538\n",
      "Epoch 214/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4638 - accuracy: 0.5102 - auc: 0.7226 - precision: 0.4389 - recall: 0.9452 - val_loss: 0.8505 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.78538\n",
      "Epoch 215/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2261 - accuracy: 0.5021 - auc: 0.7337 - precision: 0.4186 - recall: 0.9549 - val_loss: 0.8470 - val_accuracy: 0.4873 - val_auc: 0.7061 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.78538\n",
      "Epoch 216/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2349 - accuracy: 0.5108 - auc: 0.7437 - precision: 0.4361 - recall: 0.9599 - val_loss: 0.8488 - val_accuracy: 0.4873 - val_auc: 0.7045 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.78538\n",
      "Epoch 217/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3623 - accuracy: 0.5285 - auc: 0.7325 - precision: 0.4581 - recall: 0.9500 - val_loss: 0.8499 - val_accuracy: 0.4873 - val_auc: 0.7014 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.78538\n",
      "Epoch 218/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0387 - accuracy: 0.4964 - auc: 0.7477 - precision: 0.4064 - recall: 0.9579 - val_loss: 0.8557 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.78538\n",
      "Epoch 219/1000\n",
      "Learning rate:  1.0000001e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5432 - accuracy: 0.5099 - auc: 0.7013 - precision: 0.4341 - recall: 0.9713 - val_loss: 0.8509 - val_accuracy: 0.4873 - val_auc: 0.7027 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.78538\n",
      "Epoch 220/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8356 - accuracy: 0.5003 - auc: 0.7595 - precision: 0.4222 - recall: 0.9677 - val_loss: 0.8521 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.78538\n",
      "Epoch 221/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4674 - accuracy: 0.5241 - auc: 0.7319 - precision: 0.4484 - recall: 0.9450 - val_loss: 0.8559 - val_accuracy: 0.4873 - val_auc: 0.7016 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.78538\n",
      "Epoch 222/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4014 - accuracy: 0.5069 - auc: 0.7226 - precision: 0.4268 - recall: 0.9624 - val_loss: 0.8529 - val_accuracy: 0.4836 - val_auc: 0.7020 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.78538\n",
      "Epoch 223/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1509 - accuracy: 0.4968 - auc: 0.7452 - precision: 0.4177 - recall: 0.9643 - val_loss: 0.8561 - val_accuracy: 0.4836 - val_auc: 0.7044 - val_precision: 0.4170 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.78538\n",
      "Epoch 224/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2248 - accuracy: 0.5170 - auc: 0.7465 - precision: 0.4426 - recall: 0.9642 - val_loss: 0.8526 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.78538\n",
      "Epoch 225/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2531 - accuracy: 0.5179 - auc: 0.7313 - precision: 0.4357 - recall: 0.9651 - val_loss: 0.8485 - val_accuracy: 0.4873 - val_auc: 0.7050 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.78538\n",
      "Epoch 226/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2494 - accuracy: 0.5194 - auc: 0.7291 - precision: 0.4351 - recall: 0.9605 - val_loss: 0.8481 - val_accuracy: 0.4873 - val_auc: 0.7078 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.78538\n",
      "Epoch 227/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1372 - accuracy: 0.5093 - auc: 0.7492 - precision: 0.4317 - recall: 0.9572 - val_loss: 0.8496 - val_accuracy: 0.4873 - val_auc: 0.7070 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.78538\n",
      "Epoch 228/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9587 - accuracy: 0.5032 - auc: 0.7575 - precision: 0.4263 - recall: 0.9646 - val_loss: 0.8503 - val_accuracy: 0.4873 - val_auc: 0.7059 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.78538\n",
      "Epoch 229/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3293 - accuracy: 0.4893 - auc: 0.7239 - precision: 0.4177 - recall: 0.9503 - val_loss: 0.8479 - val_accuracy: 0.4873 - val_auc: 0.7075 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.78538\n",
      "Epoch 230/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2146 - accuracy: 0.5072 - auc: 0.7365 - precision: 0.4297 - recall: 0.9507 - val_loss: 0.8550 - val_accuracy: 0.4873 - val_auc: 0.7061 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.78538\n",
      "Epoch 231/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3329 - accuracy: 0.5038 - auc: 0.7314 - precision: 0.4254 - recall: 0.9663 - val_loss: 0.8458 - val_accuracy: 0.4873 - val_auc: 0.7060 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.78538\n",
      "Epoch 232/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1241 - accuracy: 0.5096 - auc: 0.7445 - precision: 0.4327 - recall: 0.9528 - val_loss: 0.8496 - val_accuracy: 0.4873 - val_auc: 0.7015 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.78538\n",
      "Epoch 233/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2572 - accuracy: 0.4992 - auc: 0.7371 - precision: 0.4244 - recall: 0.9500 - val_loss: 0.8482 - val_accuracy: 0.4873 - val_auc: 0.7039 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.78538\n",
      "Epoch 234/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2698 - accuracy: 0.5002 - auc: 0.7289 - precision: 0.4210 - recall: 0.9524 - val_loss: 0.8479 - val_accuracy: 0.4873 - val_auc: 0.7055 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.78538\n",
      "Epoch 235/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1560 - accuracy: 0.4994 - auc: 0.7407 - precision: 0.4258 - recall: 0.9591 - val_loss: 0.8492 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.78538\n",
      "Epoch 236/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9335 - accuracy: 0.5273 - auc: 0.7489 - precision: 0.4412 - recall: 0.9662 - val_loss: 0.8537 - val_accuracy: 0.4873 - val_auc: 0.7049 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.78538\n",
      "Epoch 237/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0313 - accuracy: 0.4982 - auc: 0.7537 - precision: 0.4192 - recall: 0.9586 - val_loss: 0.8514 - val_accuracy: 0.4873 - val_auc: 0.7075 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.78538\n",
      "Epoch 238/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8091 - accuracy: 0.5121 - auc: 0.7537 - precision: 0.4284 - recall: 0.9717 - val_loss: 0.8514 - val_accuracy: 0.4873 - val_auc: 0.7049 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.78538\n",
      "Epoch 239/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0876 - accuracy: 0.5179 - auc: 0.7385 - precision: 0.4341 - recall: 0.9561 - val_loss: 0.8486 - val_accuracy: 0.4873 - val_auc: 0.7055 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.78538\n",
      "Epoch 240/1000\n",
      "Learning rate:  1.0000001e-06\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1773 - accuracy: 0.5081 - auc: 0.7348 - precision: 0.4194 - recall: 0.9656 - val_loss: 0.8503 - val_accuracy: 0.4873 - val_auc: 0.7032 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.78538\n",
      "Epoch 241/1000\n",
      "Learning rate:  1.0000001111620805e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1360 - accuracy: 0.5201 - auc: 0.7490 - precision: 0.4439 - recall: 0.9615 - val_loss: 0.8508 - val_accuracy: 0.4873 - val_auc: 0.7028 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.78538\n",
      "Epoch 242/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0302 - accuracy: 0.5008 - auc: 0.7498 - precision: 0.4261 - recall: 0.9601 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7035 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.78538\n",
      "Epoch 243/1000\n",
      "Learning rate:  1.0000001e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0948 - accuracy: 0.5127 - auc: 0.7328 - precision: 0.4314 - recall: 0.9650 - val_loss: 0.8516 - val_accuracy: 0.4873 - val_auc: 0.7015 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.78538\n",
      "Epoch 244/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4498 - accuracy: 0.5112 - auc: 0.7266 - precision: 0.4345 - recall: 0.9442 - val_loss: 0.8497 - val_accuracy: 0.4836 - val_auc: 0.7030 - val_precision: 0.4163 - val_recall: 0.9417\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.78538\n",
      "Epoch 245/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2262 - accuracy: 0.5141 - auc: 0.7404 - precision: 0.4396 - recall: 0.9606 - val_loss: 0.8487 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.78538\n",
      "Epoch 246/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1762 - accuracy: 0.4961 - auc: 0.7406 - precision: 0.4114 - recall: 0.9551 - val_loss: 0.8505 - val_accuracy: 0.4873 - val_auc: 0.7035 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.78538\n",
      "Epoch 247/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3527 - accuracy: 0.5124 - auc: 0.7256 - precision: 0.4356 - recall: 0.9591 - val_loss: 0.8497 - val_accuracy: 0.4873 - val_auc: 0.7045 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.78538\n",
      "Epoch 248/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9792 - accuracy: 0.5250 - auc: 0.7435 - precision: 0.4397 - recall: 0.9752 - val_loss: 0.8475 - val_accuracy: 0.4873 - val_auc: 0.7039 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.78538\n",
      "Epoch 249/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2419 - accuracy: 0.5202 - auc: 0.7357 - precision: 0.4414 - recall: 0.9618 - val_loss: 0.8479 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.78538\n",
      "Epoch 250/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 11.9880 - accuracy: 0.5331 - auc: 0.7449 - precision: 0.4474 - recall: 0.9689 - val_loss: 0.8434 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.78538\n",
      "Epoch 251/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1048 - accuracy: 0.5213 - auc: 0.7403 - precision: 0.4403 - recall: 0.9598 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7028 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.78538\n",
      "Epoch 252/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3155 - accuracy: 0.5138 - auc: 0.7293 - precision: 0.4339 - recall: 0.9664 - val_loss: 0.8489 - val_accuracy: 0.4873 - val_auc: 0.7026 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.78538\n",
      "Epoch 253/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1138 - accuracy: 0.5006 - auc: 0.7405 - precision: 0.4183 - recall: 0.9603 - val_loss: 0.8485 - val_accuracy: 0.4873 - val_auc: 0.7059 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.78538\n",
      "Epoch 254/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0181 - accuracy: 0.5299 - auc: 0.7488 - precision: 0.4475 - recall: 0.9609 - val_loss: 0.8471 - val_accuracy: 0.4873 - val_auc: 0.7054 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.78538\n",
      "Epoch 255/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1216 - accuracy: 0.4927 - auc: 0.7406 - precision: 0.4095 - recall: 0.9677 - val_loss: 0.8470 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.78538\n",
      "Epoch 256/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1269 - accuracy: 0.5002 - auc: 0.7448 - precision: 0.4190 - recall: 0.9568 - val_loss: 0.8447 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.78538\n",
      "Epoch 257/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8887 - accuracy: 0.5087 - auc: 0.7550 - precision: 0.4247 - recall: 0.9705 - val_loss: 0.8447 - val_accuracy: 0.4873 - val_auc: 0.7034 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.78538\n",
      "Epoch 258/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0941 - accuracy: 0.5053 - auc: 0.7428 - precision: 0.4197 - recall: 0.9666 - val_loss: 0.8489 - val_accuracy: 0.4873 - val_auc: 0.7047 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.78538\n",
      "Epoch 259/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1297 - accuracy: 0.5273 - auc: 0.7423 - precision: 0.4521 - recall: 0.9623 - val_loss: 0.8482 - val_accuracy: 0.4873 - val_auc: 0.7034 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.78538\n",
      "Epoch 260/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1464 - accuracy: 0.5075 - auc: 0.7381 - precision: 0.4255 - recall: 0.9638 - val_loss: 0.8501 - val_accuracy: 0.4873 - val_auc: 0.7027 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.78538\n",
      "Epoch 261/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3267 - accuracy: 0.4940 - auc: 0.7343 - precision: 0.4237 - recall: 0.9464 - val_loss: 0.8485 - val_accuracy: 0.4873 - val_auc: 0.7050 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.78538\n",
      "Epoch 262/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2830 - accuracy: 0.5249 - auc: 0.7346 - precision: 0.4441 - recall: 0.9576 - val_loss: 0.8515 - val_accuracy: 0.4873 - val_auc: 0.7039 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.78538\n",
      "Epoch 263/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0739 - accuracy: 0.5071 - auc: 0.7471 - precision: 0.4273 - recall: 0.9634 - val_loss: 0.8463 - val_accuracy: 0.4873 - val_auc: 0.7054 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.78538\n",
      "Epoch 264/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2514 - accuracy: 0.5059 - auc: 0.7260 - precision: 0.4229 - recall: 0.9625 - val_loss: 0.8459 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.78538\n",
      "Epoch 265/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8876 - accuracy: 0.5076 - auc: 0.7568 - precision: 0.4247 - recall: 0.9632 - val_loss: 0.8464 - val_accuracy: 0.4873 - val_auc: 0.7016 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.78538\n",
      "Epoch 266/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3142 - accuracy: 0.5143 - auc: 0.7346 - precision: 0.4387 - recall: 0.9689 - val_loss: 0.8499 - val_accuracy: 0.4873 - val_auc: 0.7015 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.78538\n",
      "Epoch 267/1000\n",
      "Learning rate:  1.0000001e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3183 - accuracy: 0.5052 - auc: 0.7287 - precision: 0.4258 - recall: 0.9464 - val_loss: 0.8484 - val_accuracy: 0.4873 - val_auc: 0.7007 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.78538\n",
      "Epoch 268/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1861 - accuracy: 0.5156 - auc: 0.7402 - precision: 0.4362 - recall: 0.9607 - val_loss: 0.8467 - val_accuracy: 0.4873 - val_auc: 0.7011 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.78538\n",
      "Epoch 269/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9408 - accuracy: 0.4982 - auc: 0.7534 - precision: 0.4133 - recall: 0.9556 - val_loss: 0.8519 - val_accuracy: 0.4873 - val_auc: 0.7026 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.78538\n",
      "Epoch 270/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.6154 - accuracy: 0.4983 - auc: 0.7176 - precision: 0.4252 - recall: 0.9453 - val_loss: 0.8494 - val_accuracy: 0.4873 - val_auc: 0.7060 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.78538\n",
      "Epoch 271/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1999 - accuracy: 0.5074 - auc: 0.7416 - precision: 0.4231 - recall: 0.9618 - val_loss: 0.8440 - val_accuracy: 0.4873 - val_auc: 0.7078 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.78538\n",
      "Epoch 272/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9440 - accuracy: 0.5031 - auc: 0.7559 - precision: 0.4247 - recall: 0.9583 - val_loss: 0.8446 - val_accuracy: 0.4873 - val_auc: 0.7041 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.78538\n",
      "Epoch 273/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1741 - accuracy: 0.5074 - auc: 0.7381 - precision: 0.4315 - recall: 0.9581 - val_loss: 0.8482 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.78538\n",
      "Epoch 274/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2609 - accuracy: 0.5098 - auc: 0.7340 - precision: 0.4350 - recall: 0.9586 - val_loss: 0.8516 - val_accuracy: 0.4873 - val_auc: 0.7039 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.78538\n",
      "Epoch 275/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4376 - accuracy: 0.5115 - auc: 0.7139 - precision: 0.4309 - recall: 0.9628 - val_loss: 0.8513 - val_accuracy: 0.4873 - val_auc: 0.7048 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.78538\n",
      "Epoch 276/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0390 - accuracy: 0.5187 - auc: 0.7441 - precision: 0.4364 - recall: 0.9623 - val_loss: 0.8540 - val_accuracy: 0.4873 - val_auc: 0.7045 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.78538\n",
      "Epoch 277/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9607 - accuracy: 0.5279 - auc: 0.7503 - precision: 0.4449 - recall: 0.9699 - val_loss: 0.8492 - val_accuracy: 0.4873 - val_auc: 0.7011 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.78538\n",
      "Epoch 278/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3077 - accuracy: 0.4911 - auc: 0.7323 - precision: 0.4105 - recall: 0.9605 - val_loss: 0.8479 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.78538\n",
      "Epoch 279/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.0175 - accuracy: 0.5079 - auc: 0.7455 - precision: 0.4223 - recall: 0.9589 - val_loss: 0.8491 - val_accuracy: 0.4873 - val_auc: 0.7050 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.78538\n",
      "Epoch 280/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.9546 - accuracy: 0.5224 - auc: 0.7521 - precision: 0.4426 - recall: 0.9626 - val_loss: 0.8550 - val_accuracy: 0.4873 - val_auc: 0.7027 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.78538\n",
      "Epoch 281/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1311 - accuracy: 0.5117 - auc: 0.7403 - precision: 0.4321 - recall: 0.9644 - val_loss: 0.8502 - val_accuracy: 0.4873 - val_auc: 0.7052 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.78538\n",
      "Epoch 282/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0139 - accuracy: 0.5145 - auc: 0.7480 - precision: 0.4341 - recall: 0.9622 - val_loss: 0.8443 - val_accuracy: 0.4873 - val_auc: 0.7032 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.78538\n",
      "Epoch 283/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.4541 - accuracy: 0.4978 - auc: 0.7190 - precision: 0.4186 - recall: 0.9503 - val_loss: 0.8463 - val_accuracy: 0.4873 - val_auc: 0.7020 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.78538\n",
      "Epoch 284/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.3156 - accuracy: 0.5137 - auc: 0.7391 - precision: 0.4376 - recall: 0.9507 - val_loss: 0.8471 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.78538\n",
      "Epoch 285/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3753 - accuracy: 0.4971 - auc: 0.7276 - precision: 0.4184 - recall: 0.9487 - val_loss: 0.8490 - val_accuracy: 0.4873 - val_auc: 0.7044 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.78538\n",
      "Epoch 286/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0257 - accuracy: 0.5115 - auc: 0.7480 - precision: 0.4251 - recall: 0.9686 - val_loss: 0.8476 - val_accuracy: 0.4873 - val_auc: 0.7025 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.78538\n",
      "Epoch 287/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.4466 - accuracy: 0.5020 - auc: 0.7284 - precision: 0.4275 - recall: 0.9546 - val_loss: 0.8498 - val_accuracy: 0.4873 - val_auc: 0.7063 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.78538\n",
      "Epoch 288/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.1667 - accuracy: 0.5137 - auc: 0.7330 - precision: 0.4368 - recall: 0.9585 - val_loss: 0.8506 - val_accuracy: 0.4873 - val_auc: 0.7063 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.78538\n",
      "Epoch 289/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.2234 - accuracy: 0.5146 - auc: 0.7336 - precision: 0.4356 - recall: 0.9617 - val_loss: 0.8485 - val_accuracy: 0.4873 - val_auc: 0.7030 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.78538\n",
      "Epoch 290/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3176 - accuracy: 0.5154 - auc: 0.7382 - precision: 0.4464 - recall: 0.9551 - val_loss: 0.8491 - val_accuracy: 0.4873 - val_auc: 0.7051 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.78538\n",
      "Epoch 291/1000\n",
      "Learning rate:  1.0000001e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3535 - accuracy: 0.5262 - auc: 0.7158 - precision: 0.4514 - recall: 0.9646 - val_loss: 0.8502 - val_accuracy: 0.4873 - val_auc: 0.7031 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.78538\n",
      "Epoch 292/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3177 - accuracy: 0.5072 - auc: 0.7290 - precision: 0.4251 - recall: 0.9555 - val_loss: 0.8470 - val_accuracy: 0.4873 - val_auc: 0.7022 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.78538\n",
      "Epoch 293/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.0383 - accuracy: 0.4996 - auc: 0.7451 - precision: 0.4252 - recall: 0.9616 - val_loss: 0.8466 - val_accuracy: 0.4873 - val_auc: 0.7039 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.78538\n",
      "Epoch 294/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.2534 - accuracy: 0.5105 - auc: 0.7353 - precision: 0.4293 - recall: 0.9564 - val_loss: 0.8500 - val_accuracy: 0.4873 - val_auc: 0.7015 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.78538\n",
      "Epoch 295/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.1350 - accuracy: 0.5104 - auc: 0.7333 - precision: 0.4303 - recall: 0.9727 - val_loss: 0.8456 - val_accuracy: 0.4873 - val_auc: 0.7035 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.78538\n",
      "Epoch 296/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 11.8677 - accuracy: 0.5127 - auc: 0.7563 - precision: 0.4273 - recall: 0.9639 - val_loss: 0.8452 - val_accuracy: 0.4873 - val_auc: 0.7018 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.78538\n",
      "Epoch 297/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5099 - accuracy: 0.4858 - auc: 0.7160 - precision: 0.4111 - recall: 0.9485 - val_loss: 0.8477 - val_accuracy: 0.4873 - val_auc: 0.7033 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.78538\n",
      "Epoch 298/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.2220 - accuracy: 0.5173 - auc: 0.7332 - precision: 0.4364 - recall: 0.9557 - val_loss: 0.8535 - val_accuracy: 0.4873 - val_auc: 0.7040 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.78538\n",
      "Epoch 299/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 12.3297 - accuracy: 0.5052 - auc: 0.7348 - precision: 0.4276 - recall: 0.9553 - val_loss: 0.8550 - val_accuracy: 0.4873 - val_auc: 0.7026 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.78538\n",
      "Epoch 300/1000\n",
      "Learning rate:  1.0000001e-07\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.3464 - accuracy: 0.4807 - auc: 0.7312 - precision: 0.4014 - recall: 0.9570 - val_loss: 0.8485 - val_accuracy: 0.4873 - val_auc: 0.6993 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.78538\n",
      "Epoch 301/1000\n",
      "Learning rate:  1.000000082740371e-08\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.5687 - accuracy: 0.5043 - auc: 0.7118 - precision: 0.4275 - recall: 0.9597 - val_loss: 0.8499 - val_accuracy: 0.4873 - val_auc: 0.7035 - val_precision: 0.4188 - val_recall: 0.9515\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.78538\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.8499 - accuracy: 0.4873 - auc: 0.7035 - precision: 0.4188 - recall: 0.9515\n"
     ]
    }
   ],
   "source": [
    "AUC = tf.keras.metrics.AUC()\n",
    "prec = tf.keras.metrics.Precision()\n",
    "sens = tf.keras.metrics.Recall()\n",
    "opt = keras.optimizers.Adam(lr=0.001, beta_1=0.7, beta_2=0.8, epsilon=None, decay=0.0, amsgrad=False)\n",
    "validation_data = (x_test,y_test)\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "class_weight = {0: 10.,\n",
    "                1: 50.}\n",
    "my_lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=300)\n",
    "\n",
    "# parallel_model = multi_gpu_model(model, gpus=8)\n",
    "model.compile(loss= loss,\n",
    "              optimizer=opt,metrics=['accuracy',AUC,prec,sens]) \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/param.hdf5', verbose=1, save_best_only=True)\n",
    "dnnmodel = model.fit(x_train, y_train, validation_data=validation_data, batch_size=30, epochs = 1000, callbacks=[checkpointer,early_stopping, my_lr_scheduler], class_weight=class_weight)\n",
    "evalu = model.evaluate(x_test, y_test)\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy of training and validating \n",
    "plt.plot(dnnmodel.history['accuracy'])\n",
    "plt.plot(dnnmodel.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plot loss of training and validating \n",
    "plt.plot(dnnmodel.history['loss'])\n",
    "plt.plot(dnnmodel.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"Loss\":evalu[0],\n",
    "          \"Accuracy\":evalu[1],\n",
    "          \"AUC\":evalu[2],\n",
    "          \"Precision\":evalu[3],\n",
    "          \"Recall\":evalu[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "precision    0.426667\n",
      "sensitivity  0.516129\n",
      "accuracy     0.717054\n",
      "F1           0.467153\n",
      "specificity  0.780612\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119  53]\n",
      " [ 46  57]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE9CAYAAABwcBXnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR70lEQVR4nO3de7RWdZ2A8ed7DtPS5AgkHBtAA5FL4GQlktNcVrbMxLsNKqg15a2s7OJo2sp7ppY2pZkKXhbNmHczEW1UzDCRuGiJmhfQLCkTr0ikIfibP84WDwjHV3332fv8ej5rsc5+97vPu7+vvutZe7+X80ZKCUnKVUvVA0hSmYycpKwZOUlZM3KSsmbkJGXNyEnKmpGroYjYKSIeiohFEXFM1fOoPiLi4ohYEhH3VT1LT2HkaiYiWoEfAuOB0cCkiBhd7VSqkanATlUP0ZMYufoZByxKKT2aUloBXA7sUfFMqomU0u3As1XP0ZMYufoZBDze6fLiYp2kt8DIScqakaufPwKbdbo8uFgn6S0wcvUzDxgeEUMj4h3ARGBaxTNJPZaRq5mU0krgi8BNwAPAlSml+6udSnUREZcBs4GREbE4Ig6qeqa6C//UkqSceSQnKWtGTlLWjJykrBk5SVkzcpKyZuRqLCIOrXoG1ZOPjcYZuXrzgaz18bHRICMnKWu1ejNwn779Uvu7B1Y9Rm0sff45+vTtV/UYtdG20YZVj1AbTz/9FP37D6h6jNq4794FL6xYsaLPuq7r1d3DdKX93QM5a8rlVY+hmtp+O/92qNZt4KYDlqzvOk9XJWXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1npVPcDfq++ffjxzZ8+kb793ce7UawH45W03c+nU83j894/yvfMvZfioMQC8/PLLnHPmySx86H5aWlo49PCjed8Htq1yfHWzUSOG0da7jZbWVnr16sWs2XM46cTjueH664mWFtoHDGDyhRczcODAqketnVKP5CJip4h4KCIWRcQxZe6rp9lh/O6cfMZ5a6x7z9At+cY3/5uttt5mjfU3Tb8GgHOn/oRTvjuZC889k1deeaXbZlU9/OzmGcyZdxezZs8B4KtHHMncu37NnHl3MX7nXTjtW6dUPGE9lRa5iGgFfgiMB0YDkyJidFn762m22nosbW191li3+ZAtGLz50Ndt+4fHHmHrD44DoG+/Tejdu42FD93fLXOqvjbeeOPVy8v/upyIqHCa+irzSG4csCil9GhKaQVwObBHifvL1tBhI/nVrF+wauVK/vzEYhY9/ABPL/lz1WOpGwXBbruM58PbjeOiCy9Yvf6E449l+LAhXHHZZRx3wonVDVhjZUZuEPB4p8uLi3V6k3bceU/6t2/Klz87iSk/+A7vHbM1LS2tVY+lbjTjtpnMnjOPn06bzpTzz+OOX94OwEknn8LCRx5j30mTOP+8H1Y8ZT1V/upqRBwaEfMjYv7S55+repxaau3Vi0O/+DXOuegqjj/1bP7yl2UM2uw9VY+lbjRoUMfxQXt7O7vtsQfz581b4/qJE/fjumuvrWK02iszcn8ENut0eXCxbg0ppSkppbEppbF9+vYrcZye66WXXuSlF/8KwK/nzaa1tZXNhwyreCp1l+XLl7Ns2bLVy7fOuIXRY8awaOHC1dtMv34aI0aOrGrEWivzLSTzgOERMZSOuE0E9itxfz3Kt0/6Gvf+Zj4vLH2eT03Ygf0/83na2vpw/tmnsfT55zjxmC+wxZaj+OaZ57P0uWc57qjPEdHCJgPaOfIbp1Y9vrrRkiefZOI+EwBYuXIl+0ycyI4f34lJ++7NwocfpqWlhc0235yzzzm34knrKVJK5d14xM7A94FW4OKU0re62n74qDHprCmXlzaPerbtt/PFea3bwE0HLHruuWeHr+u6Ut8MnFK6EbixzH1IUlcqf+FBkspk5CRlzchJypqRk5Q1Iycpa0ZOUtaMnKSsGTlJWTNykrJm5CRlzchJypqRk5Q1Iycpa0ZOUtaMnKSsGTlJWTNykrJm5CRlzchJypqRk5Q1Iycpa0ZOUtaMnKSsGTlJWTNykrJm5CRlzchJypqRk5Q1Iycpa0ZOUtaMnKSsGTlJWTNykrJm5CRlzchJypqRk5Q1Iycpa0ZOUtaMnKSsGTlJWTNykrLWa31XRMQyIL16sfiZiuWUUtq45Nkk6W1bb+RSSm3dOYgklaGh09WI+NeI+Eyx3D8ihpY7liQ1xxtGLiJOAI4Gvl6segdwSZlDSVKzNHIktxewO7AcIKX0J8BTWUk9QiORW5FSShQvQkTERuWOJEnN00jkroyIyUDfiDgEmAFcUO5YktQc63119VUppTMj4mPAC8AI4PiU0i2lTyZJTfCGkSvcC2xIxynrveWNI0nN1cirqwcDc4FPABOAX0XEgWUPJknN0MiR3FHAB1JKzwBExCbAncDFZQ4mSc3QyAsPzwDLOl1eVqyTpNrr6rOrRxSLi4A5EXEdHc/J7QEs6IbZJOlt6+p09dU3/D5S/HvVdeWNI0nN1dUH9E/qzkEkqQxv+MJDRAwAvgaMATZ4dX1K6aMlziVJTdHICw8/Bh4EhgInAY8B80qcSZKappHIbZJSugh4OaU0M6V0IOBRnKQeoZH3yb1c/HwiInYB/gS8q7yRJKl5GoncKRHRB/gv4AfAxsBXS51KkpqkkQ/oTy8WlwLblzuOJDVXV28G/gGvfZHN66SUvlTKRJLURF0dyc3vtikKfXpvyMf/9Z+6e7fqIV5csarqEVRT6z0ao+s3A/+ohFkkqVv55dKSsmbkJGXNyEnKWiN/GXhERNwaEfcVl98XEceWP5okvX2NHMldQMcXS78MkFJaAEwscyhJapZGIvfOlNLctdatLGMYSWq2RiL3dEQM47Uvl54APFHqVJLUJI18dvULwBRgVET8EfgdcECpU0lSkzTy2dVHgR0iYiOgJaW07I1+R5LqopG/DHz8WpcBSCmdXNJMktQ0jZyuLu+0vAGwK/BAOeNIUnM1crr63c6XI+JM4KbSJpKkJnorn3h4JzC42YNIUhkaeU7uXl77SyatwADA5+Mk9QiNPCe3a6fllcCTKSXfDCypR+gychHRCtyUUhrVTfNIUlN1+ZxcSmkV8FBEbN5N80hSUzVyutoPuD8i5tLp7SQppd1Lm0qSmqSRyB1X+hSSVJJGIrdzSunozisi4tvAzHJGkqTmaeR9ch9bx7rxzR5EksrQ1feuHgZ8HtgiIhZ0uqoNmFX2YJLUDF2drl4K/Aw4DTim0/plKaVnS51Kkpqkq+9dXQosBSZ13ziS1Fx+W5ekrBk5SVkzcpKyZuQkZc3IScqakZOUNSMnKWtGTlLWjJykrBk5SVkzcpKyZuQkZc3IScqakZOUNSMnKWtGTlLWjJykrBk5SVkzcpKyZuQkZc3IScqakZOUNSMnKWtGTlLWjJykrBk5SVkzcpKyZuQkZc3IScqakZOUNSMnKWtGTlLWjJykrBk5SVkzcpKyZuQkZc3IScpar6oH0GtWrVrFh8aNZeDAQUy7fjopJY477liuufoqWltb+eznDuPww79U9ZiqwJiRw+jd1kZrayu9evXi9llz+M8DJrFw4cMALH3+efr07cudc+6qeNL6KS1yEXExsCuwJKW0VVn7ycnZZ5/FqFHv5YUXXgDgR1Onsvjxx7n/tw/S0tLCkiVLKp5QVbrh/2bQv3//1Zd/dMllq5e/fvSR9OnTp4qxaq/M09WpwE4l3n5WFi9ezI033sCBBx28et35k8/j2OOOp6Wl439Te3t7VeOpxlJKXHvN1UzYZ2LVo9RSaZFLKd0OPFvW7efmiK9+hdNP/87qoAE8+sgjXHnlFXxo3Fh22Xk8CxcurHBCVSki2HO38fzbh8dx8UUXrHHdrFm/pH3TTdlyy+EVTVdvvvBQA9OnT6e9vZ1tttlmjfV/+9vf2GCDDZgzdz4HH3wIBx98YEUTqmo33zqTO2bP4yc/nc4Fk8/jjjtuX33d1VdewYS9961wunqrPHIRcWhEzI+I+U899VTV41Tizjtncf310xi2xRD2328it932cz71yQMYPHgwe+31CQD23Gsv7l2woOJJVZWBgwYBMKC9nd1234O75s0DYOXKlUy77lr+Y8I+VY5Xa5VHLqU0JaU0NqU0dsCAAVWPU4lTTz2N3/9hMY88+hg/vvRytt/+o/zP/17C7nvsyS9uuw2AmTNnMmLEiIonVRWWL1/OsmXLVi/fOuMWRo8ZA8BtP5/BiBEjGTR4cJUj1ppvIamxo48+hk8esD9nnfU9Nurdm8lTLqx6JFVgyZIn2W/fCUDHkds++07kYzt2vKZ39VVXsrcvOHQpUkrl3HDEZcBHgP7Ak8AJKaWLuvqdsWPHpjlz55cyj3q+F1esqnoE1dTgfxyw6Pnnnl3nKy+lHcmllCaVdduS1KjKn5OTpDIZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrRk5S1oycpKwZOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylrkVKqeobVIuIp4PdVz1Ej/YGnqx5CteRjY03vSSkNWNcVtYqc1hQR81NKY6ueQ/XjY6Nxnq5KypqRk5Q1I1dvU6oeoBki4iMRMb1Y3j0ijuli274R8fm3sI8TI+LIRtevtc3UiJjwJvY1JCLue7MzNlkWj43uYORqLKVU6wdyRLS+2d9JKU1LKZ3exSZ9gTcdub83dX9s1ImR0+sURyoPRsSPI+KBiLg6It5ZXPdYRHw7Iu4G9o6IHSNidkTcHRFXRUTvYruditu4G/hEp9v+dEScUyxvGhHXRsQ9xb8PA6cDwyLiNxFxRrHdURExLyIWRMRJnW7rGxHxcETcAYxs4H4dUtzOPRFxzav3qbBDRMwvbm/XYvvWiDij074/+3b/26r7GTmtz0jg3JTSe4EXWPPo6pmU0geBGcCxwA7F5fnAERGxAXABsBuwDfDu9ezjbGBmSmlr4IPA/cAxwCMppfenlI6KiB2B4cA44P3ANhHx7xGxDTCxWLczsG0D9+knKaVti/09ABzU6bohxT52Ac4v7sNBwNKU0rbF7R8SEUMb2I9qpFfVA6i2Hk8pzSqWLwG+BJxZXL6i+LkdMBqYFREA7wBmA6OA36WUFgJExCXAoevYx0eBTwGklFYBSyOi31rb7Fj8+3VxuTcd0WsDrk0p/bXYx7QG7tNWEXEKHafEvYGbOl13ZUrpFWBhRDxa3Icdgfd1er6uT7HvhxvYl2rCyGl91n4DZefLy4ufAdySUprUecOIeH8T5wjgtJTS5LX28ZW3cFtTgT1TSvdExKeBj3S6bl33N4DDU0qdY0hEDHkL+1ZFPF3V+mweEf9cLO8H3LGObX4F/EtEbAkQERtFxAjgQWBIRAwrtpu0jt8FuBU4rPjd1ojoAyyj4yjtVTcBB3Z6rm9QRLQDtwN7RsSGEdFGx6nxG2kDnoiIfwD2X+u6vSOipZh5C+ChYt+HFdsTESMiYqMG9qMaMXJan4eAL0TEA0A/4Ly1N0gpPQV8GrgsIhZQnKqmlF6i4/T0huKFhyXr2ceXge0j4l7gLmB0SukZOk5/74uIM1JKNwOXArOL7a4G2lJKd9Nx2nwP8DNgXgP36ThgDjCLjhB39gdgbnFbnyvuw4XAb4G7i7eMTMaznx7Hj3XpdYrTsekppa2qnkV6uzySk5Q1j+QkZc0jOUlZM3KSsmbkJGXNyEnKmpGTlDUjJylr/w/b0OcUSvNvUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "precision    0.518182\n",
      "sensitivity  0.553398\n",
      "accuracy     0.640000\n",
      "F1           0.535211\n",
      "specificity  0.691860\n",
      "[[119  53]\n",
      " [ 46  57]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# result of testing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "thre = 0.78\n",
    "\n",
    "y_class = []\n",
    "for i in y_pred:\n",
    "    if i[0] > thre:\n",
    "        y_class.append(1)\n",
    "    else:\n",
    "        y_class.append(0)\n",
    "    \n",
    "CM = confusion_matrix(y_test,y_class)\n",
    "print(CM)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(CM, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(CM.shape[0]):\n",
    "    for j in range(CM.shape[1]):\n",
    "        ax.text(x=j, y=i, s=CM[i,j], va='center', ha='center')\n",
    "\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "precision = TP/(TP+FP)\n",
    "sensitivity = TP/(TP+FN)\n",
    "accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "specificity = TN/(TN+FP)\n",
    "F1 = 2*precision*sensitivity / (precision+sensitivity)\n",
    "\n",
    "result = pd.DataFrame([precision, sensitivity, accuracy, F1, specificity], index = ['precision', 'sensitivity', 'accuracy', 'F1', 'specificity'])\n",
    "\n",
    "\n",
    "plt.xlabel('predicted label')        \n",
    "plt.ylabel('true label')\n",
    "plt.show()\n",
    "print(result)\n",
    "print(CM)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, tre = precision_recall_curve(y_test, y_pred)\n",
    "def plot_prec_recall_vs_tresh(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label='precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g--', label = 'recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "plot_prec_recall_vs_tresh(prec, rec, tre)\n",
    "plt.savefig('PR_threshold_0420.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0\n",
      "precision    0.426667\n",
      "sensitivity  0.516129\n",
      "accuracy     0.717054\n",
      "F1           0.467153\n",
      "specificity  0.780612\n",
      "[[153  43]\n",
      " [ 30  32]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# result of validating\n",
    "y_pred = model.predict(x_valid)\n",
    "\n",
    "y_class = []\n",
    "for i in y_pred:\n",
    "    if i[0] > 0.815:\n",
    "        y_class.append(1)\n",
    "    else:\n",
    "        y_class.append(0)\n",
    "    \n",
    "CM = confusion_matrix(y_valid,y_class)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(CM, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(CM.shape[0]):\n",
    "    for j in range(CM.shape[1]):\n",
    "        ax.text(x=j, y=i, s=CM[i,j], va='center', ha='center')\n",
    "\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "precision = TP/(TP+FP)\n",
    "sensitivity = TP/(TP+FN)\n",
    "accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "specificity = TN/(TN+FP)\n",
    "F1 = 2*precision*sensitivity / (precision+sensitivity)\n",
    "\n",
    "result = pd.DataFrame([precision, sensitivity, accuracy, F1, specificity], index = ['precision', 'sensitivity', 'accuracy', 'F1', 'specificity'])\n",
    "\n",
    "\n",
    "plt.xlabel('predicted label')        \n",
    "plt.ylabel('true label')\n",
    "plt.show()\n",
    "print(result)\n",
    "print(CM)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, tre = precision_recall_curve(y_valid, y_pred)\n",
    "def plot_prec_recall_vs_tresh(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label='precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g--', label = 'recall')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "plot_prec_recall_vs_tresh(prec, rec, tre)\n",
    "plt.savefig('PR_threshold_0420.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924\n",
      "1540\n",
      "103\n",
      "172\n",
      "62\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train==True]))\n",
    "print(len(y_train[y_train==False]))\n",
    "print(len(y_test[y_test==True]))\n",
    "print(len(y_test[y_test==False]))\n",
    "print(len(y_valid[y_valid==True]))\n",
    "print(len(y_valid[y_valid==False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.5988372093023255\n",
      "0.3163265306122449\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train==True])/len(y_train[y_train==False]))\n",
    "print(len(y_test[y_test==True])/len(y_test[y_test==False]))\n",
    "print(len(y_valid[y_valid==True])/len(y_valid[y_valid==False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "count  62.000000\n",
      "mean    0.780156\n",
      "std     0.173403\n",
      "min     0.170243\n",
      "25%     0.726681\n",
      "50%     0.818724\n",
      "75%     0.910278\n",
      "max     0.955635\n",
      "                0\n",
      "count  195.000000\n",
      "mean     0.656346\n",
      "std      0.204762\n",
      "min      0.033659\n",
      "25%      0.545332\n",
      "50%      0.738370\n",
      "75%      0.803800\n",
      "max      0.953779\n"
     ]
    }
   ],
   "source": [
    "#describing values of classfication \n",
    "true_thre = []\n",
    "false_thre = []\n",
    "for i in range(0, len(y_pred)-1):\n",
    "    if y_valid[i] == True:\n",
    "        true_thre.append(y_pred[i][0])\n",
    "    else:\n",
    "        false_thre.append(y_pred[i][0])\n",
    "        \n",
    "true = pd.DataFrame(true_thre)\n",
    "false = pd.DataFrame(false_thre)\n",
    "print(true.describe())\n",
    "print(false.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save('dnn.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot predicted vs true\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "ax.scatter(y_pred, y_valid, color=\"black\")\n",
    "abline_plot(intercept=0, slope=1, color=\"red\", ax=ax)\n",
    "# ax[0].vlines(x=y_pred.max(), ymin=y_valid.max(), ymax=max_true-max_error, color='red', linestyle='--', alpha=0.7, label=\"max error\")\n",
    "ax.grid(True)\n",
    "ax.set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Predicted vs True\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot lime\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "x_ary = x_train.to_numpy()\n",
    "val_ary = x_valid.to_numpy()\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(x_train.values, \n",
    "                                                   feature_names=x_columns, \n",
    "                                                   class_names=['values'], \n",
    "                                                   verbose=True,  discretize_continuous=True)\n",
    "\n",
    "for i in range(0, len(val_ary)-1):\n",
    "    exp = explainer.explain_instance(val_ary[i], \n",
    "                                     model.predict, \n",
    "                                     num_features=10,\n",
    "                                     top_labels=10)\n",
    "#     exp.show_in_notebook(show_table=True)\n",
    "print(y_pred[i], y_test.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot shap\n",
    "import shap\n",
    "import ipywidgets as widgets\n",
    "\n",
    "idx = 100\n",
    "\n",
    "explainer = shap.KernelExplainer(model = model.predict, data = x_train, link = \"identity\")\n",
    "\n",
    "shap_values = explainer.shap_values(x_train)\n",
    "# list_of_labels = y_valid.to_list()\n",
    "# tuple_of_labels = list(zip(list_of_labels, range(len(list_of_labels))))\n",
    "# current_label = widgets.Dropdown(options=tuple_of_labels,\n",
    "#                               value=0,\n",
    "#                               description='Select Label:')\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_train)\n",
    "# shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
